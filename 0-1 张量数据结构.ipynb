{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、张量数据结构\n",
    "张量的数据类型和numpy.array基本一一对应，但是不支持str类型。\n",
    "\n",
    "包括:\n",
    "\n",
    "torch.float64(torch.double),\n",
    "\n",
    "torch.float32(torch.float),\n",
    "\n",
    "torch.float16,\n",
    "\n",
    "torch.int64(torch.long),\n",
    "\n",
    "torch.int32(torch.int),\n",
    "\n",
    "torch.int16,\n",
    "\n",
    "torch.int8,\n",
    "\n",
    "torch.uint8,\n",
    "\n",
    "torch.bool\n",
    "\n",
    "一般神经网络建模使用的都是torch.float32(torch.float)类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1) torch.int64\n",
      "tensor(2.) torch.float32\n",
      "tensor(True) torch.bool\n"
     ]
    }
   ],
   "source": [
    "# 自动判断类型\n",
    "\n",
    "t1 = torch.tensor(1); print(t1, t1.dtype)\n",
    "t2 = torch.tensor(2.0); print(t2, t2.dtype)\n",
    "t3 = torch.tensor(True); print(t3, t3.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1, dtype=torch.int32) torch.int32\n",
      "tensor(2., dtype=torch.float64) torch.float64\n"
     ]
    }
   ],
   "source": [
    "# 指定数据类型\n",
    "\n",
    "t4 = torch.tensor(1, dtype = torch.int32); print(t4, t4.dtype)\n",
    "t5 = torch.tensor(2.0, dtype = torch.double); print(t5, t5.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1828150782], dtype=torch.int32) torch.int32 torch.IntTensor\n",
      "tensor(2.) torch.float32 torch.FloatTensor\n",
      "tensor([ True, False,  True, False]) torch.bool torch.BoolTensor\n"
     ]
    }
   ],
   "source": [
    "# 使用特定类型构造函数\n",
    "\n",
    "t6 = torch.IntTensor(1); print(t6, t6.dtype, t6.type())\n",
    "t7 = torch.Tensor(np.array(2.0)); print(t7, t7.dtype, t7.type()) \n",
    "# torch.tensor根据data自动判断类型；torch.Tensor生成固定类型的FloatTensor\n",
    "\n",
    "t8 = torch.BoolTensor(np.array([1, 0, 2, 0])); print(t8, t8.dtype, t8.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1) torch.int64\n",
      "tensor(1.) torch.float32\n",
      "tensor(1.) torch.float32\n",
      "tensor(1.) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# 不同类型转换\n",
    "\n",
    "t9 = torch.tensor(1); print(t9, t9.dtype)\n",
    "x = t9.float(); print(x, x.dtype) # 调用float方法转换成浮点类型\n",
    "y = t9.type(torch.float); print(y, y.dtype) #使用type函数转换成浮点类型\n",
    "z = t9.type_as(x); print(z, z.dtype) #使用type_as方法转换成某个tensor相同的类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、张量的维度\n",
    "不同类型的数据可以用不同维度(dimension)的张量来表示。\n",
    "\n",
    "标量为0维张量，向量为1维张量，矩阵为2维张量。\n",
    "\n",
    "彩色图像有rgb三个通道，可以表示为3维张量。\n",
    "\n",
    "视频还有时间维，可以表示为4维张量。\n",
    "\n",
    "可以简单地总结为：有几层中括号，就是多少维的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "0\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "scalar = torch.tensor(True)\n",
    "print(scalar)\n",
    "print(scalar.dim()) # 标量，0维张量\n",
    "print(scalar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.])\n",
      "1\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "vector = torch.tensor([1.0, 2.0, 3.0, 4.0]) #向量，1维张量\n",
    "print(vector)\n",
    "print(vector.dim())\n",
    "print(vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "2\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "matrix = torch.tensor([[1.0, 2.0], \n",
    "                       [3.0, 4.0]]) #矩阵, 2维张量\n",
    "print(matrix)\n",
    "print(matrix.dim())\n",
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 2.],\n",
      "         [3., 4.]],\n",
      "\n",
      "        [[5., 6.],\n",
      "         [7., 8.]]])\n",
      "3\n",
      "torch.Size([2, 2, 2])\n",
      "\n",
      "\n",
      "tensor([[[0.1577, 0.4496],\n",
      "         [0.7152, 0.1112]],\n",
      "\n",
      "        [[0.4229, 0.9447],\n",
      "         [0.7538, 0.2481]],\n",
      "\n",
      "        [[0.5383, 0.9819],\n",
      "         [0.3493, 0.4386]]])\n",
      "3\n",
      "torch.Size([3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor3 = torch.tensor([[[1.0, 2.0], [3.0, 4.0]], [[5.0, 6.0], [7.0, 8.0]]])  # 3维张量\n",
    "tensor3_1 = torch.rand(3, 2, 2)\n",
    "\n",
    "print(tensor3)\n",
    "print(tensor3.dim())\n",
    "print(tensor3.shape) # 理解为2个2*2矩阵拼接成一个3维张量\n",
    "print('\\n')\n",
    "print(tensor3_1)\n",
    "print(tensor3_1.dim())\n",
    "print(tensor3_1.shape) # 理解为3个2*2矩阵拼接成一个3维张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1.],\n",
      "          [2., 2.]],\n",
      "\n",
      "         [[3., 3.],\n",
      "          [4., 4.]]],\n",
      "\n",
      "\n",
      "        [[[5., 5.],\n",
      "          [6., 6.]],\n",
      "\n",
      "         [[7., 7.],\n",
      "          [8., 8.]]]])\n",
      "4\n",
      "torch.Size([2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "tensor4 = torch.tensor([[[[1.0, 1.0], [2.0,2.0]], [[3.0, 3.0], [4.0, 4.0]]],\n",
    "                        [[[5.0, 5.0], [6.0,6.0]], [[7.0, 7.0], [8.0, 8.0]]]])  # 4维张量\n",
    "print(tensor4)\n",
    "print(tensor4.dim())\n",
    "print(tensor4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、张量的尺寸\n",
    "shape属性查看张量的尺寸\n",
    "\n",
    "size()方法查看张量在每一维的长度\n",
    "\n",
    "使用view方法改变张量的尺寸。如果view方法改变尺寸失败，可以使用reshape方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "scalar = torch.tensor(True)\n",
    "print(scalar.size())\n",
    "print(scalar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "vector = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "print(vector.size())\n",
    "print(vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "matrix = torch.tensor([[1.0,2.0],[3.0,4.0]])\n",
    "print(matrix.size())\n",
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2440, 0.5094],\n",
      "         [0.6609, 0.2784]],\n",
      "\n",
      "        [[0.3684, 0.6799],\n",
      "         [0.9825, 0.8350]],\n",
      "\n",
      "        [[0.1412, 0.7738],\n",
      "         [0.0751, 0.8754]]])\n",
      "torch.Size([3, 2, 2])\n",
      "torch.Size([3, 2, 2])\n",
      "3\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "tensor3 = torch.rand(3, 2, 2)  # 3维张量\n",
    "print(tensor3)\n",
    "print(tensor3.shape)\n",
    "print(tensor3.size())\n",
    "print(tensor3.size(0))\n",
    "print(tensor3.size(1))\n",
    "print(tensor3.size(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "torch.Size([12])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "torch.Size([3, 4])\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "torch.Size([4, 3])\n",
      "tensor([[[ 0,  1],\n",
      "         [ 2,  3],\n",
      "         [ 4,  5]],\n",
      "\n",
      "        [[ 6,  7],\n",
      "         [ 8,  9],\n",
      "         [10, 11]]])\n",
      "torch.Size([2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# 使用view可以改变张量尺寸\n",
    "\n",
    "vector = torch.arange(0, 12)\n",
    "print(vector)\n",
    "print(vector.shape)\n",
    "\n",
    "matrix34 = vector.view(3, 4)\n",
    "print(matrix34)\n",
    "print(matrix34.shape)\n",
    "\n",
    "matrix43 = vector.view(4, -1) #-1表示该位置长度由程序自动推断\n",
    "print(matrix43)\n",
    "print(matrix43.shape)\n",
    "\n",
    "matrix232 = vector.view(2, 3, -1)\n",
    "print(matrix232)\n",
    "print(matrix232.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11]])\n",
      "torch.Size([2, 6])\n",
      "tensor([[ 0,  6],\n",
      "        [ 1,  7],\n",
      "        [ 2,  8],\n",
      "        [ 3,  9],\n",
      "        [ 4, 10],\n",
      "        [ 5, 11]])\n",
      "False\n",
      "tensor([[ 0,  6,  1,  7],\n",
      "        [ 2,  8,  3,  9],\n",
      "        [ 4, 10,  5, 11]])\n"
     ]
    }
   ],
   "source": [
    "# 有些操作会让张量存储结构扭曲，直接使用view会失败，可以用reshape方法\n",
    "\n",
    "matrix26 = torch.arange(0, 12).view(2, 6)\n",
    "print(matrix26)\n",
    "print(matrix26.shape)\n",
    "\n",
    "# 转置操作让张量存储结构扭曲\n",
    "matrix62 = matrix26.t()\n",
    "print(matrix62)\n",
    "print(matrix62.is_contiguous())\n",
    "\n",
    "# 直接使用view方法会失败，可以使用reshape方法\n",
    "# matrix34 = matrix62.view(3, 4) #error!\n",
    "matrix34 = matrix62.reshape(3, 4) #等价于matrix34 = matrix62.contiguous().view(3,4)\n",
    "print(matrix34)\n",
    "\n",
    "# print(matrix62.view(3, 4))# error!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、张量和numpy数组\n",
    "可以用numpy方法从Tensor得到numpy数组，也可以用torch.from_numpy从numpy数组得到Tensor。\n",
    "\n",
    "这两种方法关联的Tensor和numpy数组是共享数据内存的。\n",
    "\n",
    "如果改变其中一个，另外一个的值也会发生改变。\n",
    "\n",
    "如果有需要，可以用张量的clone方法拷贝张量，中断这种关联。\n",
    "\n",
    "此外，还可以使用item方法从标量张量得到对应的Python数值。\n",
    "\n",
    "使用tolist方法从张量得到对应的Python数值列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before add 1:\n",
      "[0. 0. 0.]\n",
      "tensor([0., 0., 0.], dtype=torch.float64)\n",
      "\n",
      "after add 1:\n",
      "[1. 1. 1.]\n",
      "tensor([1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 从numpy数组得到tensor：torch.from_numpy\n",
    "\n",
    "arr = np.zeros(3)\n",
    "tensor = torch.from_numpy(arr)\n",
    "print('before add 1:')\n",
    "print(arr)\n",
    "print(tensor)\n",
    "\n",
    "print('\\nafter add 1:')\n",
    "np.add(arr, 1, out = arr) # arr和tensor共享内存，改变一方另一方也改变\n",
    "print(arr)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before add 1:\n",
      "tensor([0., 0., 0.])\n",
      "[0. 0. 0.]\n",
      "\n",
      "after add 1:\n",
      "tensor([1., 1., 1.])\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# 从tensor得到numpy数组：numpy()\n",
    "\n",
    "tensor = torch.zeros(3)\n",
    "arr = tensor.numpy()\n",
    "print('before add 1:')\n",
    "print(tensor)\n",
    "print(arr)\n",
    "\n",
    "print('\\nafter add 1:')\n",
    "\n",
    "tensor.add_(1) # 使用带下划线的方法表示计算结果会返回给调用张量\n",
    "# 等价于 torch.add(tensor, 1, out = tensor)\n",
    "print(tensor)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before add 1:\n",
      "tensor([0., 0., 0.])\n",
      "[0. 0. 0.]\n",
      "\n",
      "after add 1:\n",
      "tensor([1., 1., 1.])\n",
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 要中断这种关联，使用clone()方法\n",
    "\n",
    "tensor = torch.zeros(3)\n",
    "\n",
    "# 使用clone方法拷贝张量, 拷贝后的张量和原始张量内存独立\n",
    "\n",
    "print('before add 1:')\n",
    "arr = tensor.clone().numpy()\n",
    "print(tensor)\n",
    "print(arr)\n",
    "\n",
    "print('\\nafter add 1:')\n",
    "torch.add(tensor, 1, out = tensor)\n",
    "print(tensor)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "<class 'float'>\n",
      "\n",
      "\n",
      "tensor([[0.8363, 0.8089],\n",
      "        [0.2180, 0.3343]])\n",
      "[[0.8362599015235901, 0.8089374303817749], [0.21795809268951416, 0.3342616558074951]]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# item方法和tolist方法可以将张量转换成Python数值和数值列表\n",
    "\n",
    "scalar = torch.tensor(1.0)\n",
    "s = scalar.item()\n",
    "print(s)\n",
    "print(type(s))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "tensor = torch.rand(2, 2)\n",
    "t = tensor.tolist()\n",
    "print(tensor)\n",
    "print(t)\n",
    "print(type(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
