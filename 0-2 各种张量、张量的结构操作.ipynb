{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0-2 张量的结构操作\n",
    "张量的操作主要包括张量的结构操作和张量的数学运算。\n",
    "\n",
    "张量结构操作诸如：张量创建，索引切片，维度变换，合并分割。\n",
    "\n",
    "张量数学运算主要有：标量运算，向量运算，矩阵运算。张量的运算采用广播机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、创建张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3], dtype = torch.float)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 3, 5, 7, 9])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "b = torch.arange(1, 10, step = 2)\n",
    "print(b)\n",
    "print(b.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  3.3333,  6.6667, 10.0000])\n"
     ]
    }
   ],
   "source": [
    "# 线性间距向量\n",
    "# torch.linspace(start, end, steps=100, out=None) → Tensor \n",
    "# 返回一个1维张量，包含在区间start和end上均匀间隔的step个点。输出张量的长度由steps决定。\n",
    "\n",
    "c = torch.linspace(0, 10, steps = 4)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "d = torch.zeros(3, 3)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int32)\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((3, 3), dtype = torch.int)\n",
    "b = torch.zeros_like(a, dtype = torch.float)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 6., 6.],\n",
      "        [6., 6., 6.],\n",
      "        [6., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "torch.fill_(b, 6)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4963, 0.7682, 0.0885, 0.1320, 0.3074])\n",
      "tensor([4.9626, 7.6822, 0.8848, 1.3203, 3.0742])\n"
     ]
    }
   ],
   "source": [
    "# 均匀分布\n",
    "# torch.rand 从区间[0, 1)的均匀分布中抽取的一组随机数。\n",
    "\n",
    "torch.manual_seed(0)\n",
    "minval, maxval = 0, 10\n",
    "rand = torch.rand([5])\n",
    "a = minval + (maxval - minval)*rand\n",
    "print(rand)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5410, -0.2934],\n",
      "        [-2.1788,  0.5684],\n",
      "        [-1.0845, -1.3986]])\n"
     ]
    }
   ],
   "source": [
    "# 标准正态分布\n",
    "# torch.randn(*sizes, out=None) → Tensor \n",
    "# 返回一个张量，包含了从标准正态分布(均值为0，方差为 1，即高斯白噪声)中抽取一组随机数\n",
    "\n",
    "torch.manual_seed(0)\n",
    "print(torch.randn(3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5410, -0.2934],\n",
      "        [-2.1788,  0.5684],\n",
      "        [-1.0845, -1.3986]])\n"
     ]
    }
   ],
   "source": [
    "# 正态分布随机\n",
    "# torch.normal(means, std, out=None) \n",
    "# 返回一个张量，包含从给定参数means,std的离散正态分布中抽取随机数。 \n",
    "# 均值means是一个张量，包含每个输出元素相关的正态分布的均值。 std是一个张量，包含每个输出元素相关的正态分布的标准差。\n",
    "\n",
    "torch.manual_seed(0)\n",
    "b = torch.normal(mean = torch.zeros(3, 2), std = torch.ones(3, 2)) # mean = 0, std = 1, 即标准正态分布\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5410, -0.2934, -2.1788],\n",
      "        [ 0.5684, -1.0845, -1.3986],\n",
      "        [ 0.4033,  0.8380, -0.7193]])\n",
      "tensor([[ 9.7050,  0.5329, -8.8939],\n",
      "        [ 4.8422, -3.4226, -4.9930],\n",
      "        [ 4.0167,  6.1901, -1.5963]])\n"
     ]
    }
   ],
   "source": [
    "# 正态分布随机\n",
    "\n",
    "torch.manual_seed(0)\n",
    "mean, std = 2, 5\n",
    "randn = torch.randn((3, 3))\n",
    "c = std * randn + mean \n",
    "print(randn)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9.7050,  0.5329, -8.8939],\n",
      "        [ 4.8422, -3.4226, -4.9930],\n",
      "        [ 4.0167,  6.1901, -1.5963]])\n"
     ]
    }
   ],
   "source": [
    "# 上面c等价于c_1\n",
    "\n",
    "torch.manual_seed(0)\n",
    "mean = torch.fill_(torch.zeros((3, 3)), 2)\n",
    "std = torch.fill_(torch.zeros((3, 3)), 5)\n",
    "c_1 = torch.normal(mean = mean, std = std)\n",
    "print(c_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6, 19,  1,  8, 12, 16,  7,  9, 17, 18, 11, 10, 15,  0,  4, 14, 13,  2,\n",
      "         3,  5])\n"
     ]
    }
   ],
   "source": [
    "# 整数随机排列\n",
    "# torch.randperm(n, out=None) → LongTensor\n",
    "# 给定参数n，返回一个从0到n-1的随机整数排列。参数n：int，上边界（不包含）\n",
    "\n",
    "d = torch.randperm(20)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([[1, 0, 0],\n",
      "        [0, 2, 0],\n",
      "        [0, 0, 3]])\n"
     ]
    }
   ],
   "source": [
    "# 特殊矩阵\n",
    "\n",
    "# 单位阵\n",
    "I = torch.eye(3, 3)\n",
    "print(I)\n",
    "\n",
    "# 对角阵\n",
    "t = torch.diag(torch.tensor([1, 2, 3]))\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、索引切片\n",
    "张量的索引切片方式和numpy几乎是一样的。切片时支持缺省参数和省略号。\n",
    "\n",
    "可以通过索引和切片对部分元素进行修改。\n",
    "\n",
    "此外，对于不规则的切片提取,可以使用torch.index_select, torch.masked_select, torch.take\n",
    "\n",
    "如果要通过修改张量的某些元素得到新的张量，可以使用torch.where, torch.masked_fill, torch.index_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074],\n",
      "        [0.6341, 0.4901, 0.8964, 0.4556, 0.6323],\n",
      "        [0.3489, 0.4017, 0.0223, 0.1689, 0.2939],\n",
      "        [0.5185, 0.6977, 0.8000, 0.1610, 0.2823],\n",
      "        [0.6816, 0.9152, 0.3971, 0.8742, 0.4194]])\n",
      "tensor([[4.9626, 7.6822, 0.8848, 1.3203, 3.0742],\n",
      "        [6.3408, 4.9009, 8.9644, 4.5563, 6.3231],\n",
      "        [3.4889, 4.0172, 0.2233, 1.6886, 2.9389],\n",
      "        [5.1852, 6.9767, 8.0001, 1.6103, 2.8227],\n",
      "        [6.8161, 9.1519, 3.9710, 8.7416, 4.1941]])\n",
      "tensor([[4, 7, 0, 1, 3],\n",
      "        [6, 4, 8, 4, 6],\n",
      "        [3, 4, 0, 1, 2],\n",
      "        [5, 6, 8, 1, 2],\n",
      "        [6, 9, 3, 8, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 均匀分布\n",
    "\n",
    "torch.manual_seed(0)\n",
    "minval, maxval = 0, 10\n",
    "rand = torch.rand(5, 5)\n",
    "input_tensor = minval + (maxval - minval)*rand\n",
    "t = torch.floor(input_tensor).int()\n",
    "\n",
    "print(rand)\n",
    "print(input_tensor)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 7, 0, 1, 3], dtype=torch.int32)\n",
      "tensor([6, 9, 3, 8, 4], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 第0行\n",
    "print(t[0])\n",
    "\n",
    "# 倒数第一行\n",
    "print(t[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4, dtype=torch.int32)\n",
      "tensor(4, dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 第1行第3列\n",
    "print(t[1, 3])\n",
    "print(t[1][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 4, 8, 4, 6],\n",
      "        [3, 4, 0, 1, 2],\n",
      "        [5, 6, 8, 1, 2]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 第1行至第3行\n",
    "print(t[1:4, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 8],\n",
      "        [3, 0],\n",
      "        [5, 8]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 第1行至第3行，第0列到第3列一列每隔两列取一列\n",
    "print(t[1:4, :4:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [0., 0.]], requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#可以使用索引和切片修改部分元素\n",
    "x = torch.tensor([[1, 2], [3, 4]], dtype = torch.float32, requires_grad=True)\n",
    "x.data[1, :] = torch.tensor([0.0, 0.0])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  7,  8]],\n",
      "\n",
      "        [[ 9, 10, 11],\n",
      "         [12, 13, 14],\n",
      "         [15, 16, 17]],\n",
      "\n",
      "        [[18, 19, 20],\n",
      "         [21, 22, 23],\n",
      "         [24, 25, 26]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(27).view(3, 3, 3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  4,  7],\n",
      "        [10, 13, 16],\n",
      "        [19, 22, 25]])\n"
     ]
    }
   ],
   "source": [
    "# 省略号可以表示多个冒号\n",
    "print(a[..., 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 关于tensor dim\n",
    "dim意为 只有dim指定的维度可变，其他都是不变的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4963, 0.7682, 0.0885],\n",
      "        [0.1320, 0.3074, 0.6341],\n",
      "        [0.4901, 0.8964, 0.4556],\n",
      "        [0.6323, 0.3489, 0.4017]])\n",
      "tensor([3, 2, 1])\n",
      "tensor([1, 2, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# torch.argmax(input, dim=None, keepdim=False)返回指定维度最大值的序号\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "a = torch.rand((4, 3))\n",
    "print(a)\n",
    "\n",
    "b = torch.argmax(a, dim = 0) # 只有dim0可变，dim1不变 -> dim1去比较\n",
    "print(b)\n",
    "\n",
    "c = torch.argmax(a, dim = 1) # 只有dim1可变，dim0不变 -> dim0去比较\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "t.sum(): tensor(15)\n",
      "t.sum(dim = 0): tensor([3, 5, 7])\n",
      "t.sum(dim = 1): tensor([ 3, 12])\n"
     ]
    }
   ],
   "source": [
    "t = torch.arange(0, 6).view(2, 3)\n",
    "print(t)\n",
    "\n",
    "print('t.sum():', t.sum())\n",
    "print('t.sum(dim = 0):', t.sum(dim = 0)) # 只有dim0可变，dim1不变，对dim1操作 = [3, 5, 7]\n",
    "print('t.sum(dim = 1):', t.sum(dim = 1)) # 只有dim1可变，dim0不变，对dim0操作 = [3, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 5, 7]])\n",
      "tensor([[ 0,  1,  3],\n",
      "        [ 3,  7, 12]])\n"
     ]
    }
   ],
   "source": [
    "# torch.cumsum(input, dim, out=None) → Tensor\n",
    "# 返回输入沿指定维度的累积和。例如，如果输入是一个N元向量，则结果也是一个N元向量，第i个输出元素值为 yi=x1+x2+x3+...+xi\n",
    "\n",
    "t = torch.arange(0, 6).view(2, 3)\n",
    "print(t)\n",
    "print(t.cumsum(dim = 0)) # 沿dim1操作：0,3 1,5 2,7\n",
    "print(t.cumsum(dim = 1)) # 沿dim0操作：0,1,3 3,7,12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考虑班级成绩册的例子，有4个班级，每个班级10个学生，每个学生7门科目成绩。可以用一个4×10×7的张量来表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2, 16, 29, 51, 69, 80, 16],\n",
      "         [28, 68, 91, 39, 87, 41, 55],\n",
      "         [95,  3, 18, 37, 30, 93, 17],\n",
      "         [26, 15,  3, 20, 92, 72, 74],\n",
      "         [52, 24, 58,  3, 13, 24, 81],\n",
      "         [79, 27, 48, 81, 99, 69, 56],\n",
      "         [83, 20, 59, 11, 15, 24, 72],\n",
      "         [70, 20, 65, 77, 43, 51, 61],\n",
      "         [81, 98, 11, 31, 69, 91, 93],\n",
      "         [94, 59,  6, 54, 18,  3, 94]],\n",
      "\n",
      "        [[88,  0, 59, 41, 41, 27, 69],\n",
      "         [20, 68, 75, 85, 68,  0, 17],\n",
      "         [74, 60, 10, 21, 97, 83, 28],\n",
      "         [37,  2, 49, 12, 11, 47, 57],\n",
      "         [29, 79, 19, 95, 84,  7, 37],\n",
      "         [52, 57, 61, 69, 52, 25, 73],\n",
      "         [ 2, 20, 37, 25, 32,  9, 39],\n",
      "         [60, 17, 47, 85, 44, 51, 45],\n",
      "         [60, 81, 97, 81, 97, 46,  5],\n",
      "         [26, 84, 49, 25, 11,  3,  7]],\n",
      "\n",
      "        [[39, 77, 77,  1, 81, 10, 39],\n",
      "         [29, 40, 40,  5,  6, 42, 50],\n",
      "         [27, 68,  4, 46, 93, 29, 95],\n",
      "         [68,  4, 81, 44, 27, 89,  9],\n",
      "         [55, 39, 85, 63, 74, 67, 37],\n",
      "         [39,  8, 77, 89, 84, 14, 52],\n",
      "         [14, 22, 20, 67, 20, 48, 52],\n",
      "         [82, 12, 15, 20, 84, 32, 92],\n",
      "         [68, 56, 49, 40, 56, 38, 49],\n",
      "         [56, 10, 23, 90,  9, 46, 99]],\n",
      "\n",
      "        [[68, 51,  6, 74, 14, 35, 33],\n",
      "         [42, 50, 91, 56, 94, 80, 18],\n",
      "         [72, 14, 28, 64, 66, 87, 33],\n",
      "         [50, 75,  1, 86,  8, 50, 41],\n",
      "         [23, 56, 91, 35, 20, 31,  0],\n",
      "         [72, 25, 16, 21, 78, 76, 88],\n",
      "         [68, 33, 36, 64, 91, 63, 26],\n",
      "         [26,  2, 60, 21,  5, 93, 17],\n",
      "         [44, 64, 51, 16,  9, 89, 58],\n",
      "         [91, 33, 64, 38, 47, 19, 66]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "minval = 0\n",
    "maxval = 100\n",
    "scores = torch.floor(minval + (maxval - minval) * torch.rand([4, 10, 7])).int()\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2, 16, 29, 51, 69, 80, 16],\n",
       "         [79, 27, 48, 81, 99, 69, 56],\n",
       "         [94, 59,  6, 54, 18,  3, 94]],\n",
       "\n",
       "        [[88,  0, 59, 41, 41, 27, 69],\n",
       "         [52, 57, 61, 69, 52, 25, 73],\n",
       "         [26, 84, 49, 25, 11,  3,  7]],\n",
       "\n",
       "        [[39, 77, 77,  1, 81, 10, 39],\n",
       "         [39,  8, 77, 89, 84, 14, 52],\n",
       "         [56, 10, 23, 90,  9, 46, 99]],\n",
       "\n",
       "        [[68, 51,  6, 74, 14, 35, 33],\n",
       "         [72, 25, 16, 21, 78, 76, 88],\n",
       "         [91, 33, 64, 38, 47, 19, 66]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 抽取每个班级第0个学生，第5个学生，第9个学生的全部成绩\n",
    "\n",
    "torch.index_select(scores, dim = 1, index = torch.tensor([0, 5, 9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[16, 51, 16],\n",
      "         [27, 81, 56],\n",
      "         [59, 54, 94]],\n",
      "\n",
      "        [[ 0, 41, 69],\n",
      "         [57, 69, 73],\n",
      "         [84, 25,  7]],\n",
      "\n",
      "        [[77,  1, 39],\n",
      "         [ 8, 89, 52],\n",
      "         [10, 90, 99]],\n",
      "\n",
      "        [[51, 74, 33],\n",
      "         [25, 21, 88],\n",
      "         [33, 38, 66]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 抽取每个班级第0个学生，第5个学生，第9个学生的第1门课程，第3门课程，第6门课程成绩\n",
    "\n",
    "q = torch.index_select(\n",
    "    torch.index_select(scores, dim = 1, index = torch.tensor([0, 5, 9])), \n",
    "    dim = 2, index = torch.tensor([1, 3, 6])\n",
    ")\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2, 39, 66], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 抽取第0个班级第0个学生的第0门课程，第2个班级的第4个学生的第1门课程，第3个班级的第9个学生第6门课程成绩\n",
    "# take将输入看成一维数组，输出和index同形状\n",
    "\n",
    "s = torch.take(scores, torch.tensor([0*10*7+0, 2*10*7+4*7+1, 3*10*7+9*7+6]))\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([80, 91, 87, 95, 93, 92, 81, 81, 99, 83, 81, 98, 91, 93, 94, 94, 88, 85,\n",
      "        97, 83, 95, 84, 85, 81, 97, 81, 97, 84, 81, 93, 95, 81, 89, 85, 89, 84,\n",
      "        82, 84, 92, 90, 99, 91, 94, 80, 87, 86, 91, 88, 91, 93, 89, 91],\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 抽取分数大于等于80分的分数（布尔索引）\n",
    "# 结果是1维张量\n",
    "\n",
    "g = torch.masked_select(scores, scores >= 80)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上这些方法仅能提取张量的部分元素值，但不能更改张量的部分元素值得到新的张量。\n",
    "\n",
    "如果要通过修改张量的部分元素值得到新的张量，可以使用torch.where, torch.index_fill 和 torch.masked_fill\n",
    "\n",
    "torch.where可以理解为if的张量版本。\n",
    "\n",
    "torch.index_fill的选取元素逻辑和torch.index_select相同。\n",
    "\n",
    "torch.masked_fill的选取元素逻辑和torch.masked_select相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 0, 0, 0, 1, 1, 0],\n",
      "         [0, 1, 1, 0, 1, 0, 0],\n",
      "         [1, 0, 0, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 0, 1, 1, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 1],\n",
      "         [1, 0, 0, 1, 1, 1, 0],\n",
      "         [1, 0, 0, 0, 0, 0, 1],\n",
      "         [1, 0, 1, 1, 0, 0, 1],\n",
      "         [1, 1, 0, 0, 1, 1, 1],\n",
      "         [1, 0, 0, 0, 0, 0, 1]],\n",
      "\n",
      "        [[1, 0, 0, 0, 0, 0, 1],\n",
      "         [0, 1, 1, 1, 1, 0, 0],\n",
      "         [1, 0, 0, 0, 1, 1, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 1, 0, 1, 1, 0, 0],\n",
      "         [0, 0, 1, 1, 0, 0, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 1, 0, 0, 0],\n",
      "         [0, 1, 1, 1, 1, 0, 0],\n",
      "         [0, 1, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 1, 1, 0, 1, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 1, 0, 1],\n",
      "         [1, 0, 1, 0, 0, 1, 0],\n",
      "         [0, 0, 1, 1, 1, 1, 0],\n",
      "         [0, 0, 1, 1, 1, 0, 0],\n",
      "         [0, 0, 0, 1, 0, 0, 0],\n",
      "         [1, 0, 0, 0, 1, 0, 1],\n",
      "         [1, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 1, 0, 0, 1]],\n",
      "\n",
      "        [[1, 0, 0, 1, 0, 0, 0],\n",
      "         [0, 0, 1, 0, 1, 1, 0],\n",
      "         [1, 0, 0, 1, 1, 1, 0],\n",
      "         [0, 1, 0, 1, 0, 0, 0],\n",
      "         [0, 0, 1, 0, 0, 0, 0],\n",
      "         [1, 0, 0, 0, 1, 1, 1],\n",
      "         [1, 0, 0, 1, 1, 1, 0],\n",
      "         [0, 0, 0, 0, 0, 1, 0],\n",
      "         [0, 1, 0, 0, 0, 1, 0],\n",
      "         [1, 0, 1, 0, 0, 0, 1]]])\n"
     ]
    }
   ],
   "source": [
    "# 如果分数大于60分，赋值成1，否则赋值成0\n",
    "ifpass = torch.where(scores > 60, torch.tensor(1), torch.tensor(0))\n",
    "print(ifpass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[100, 100, 100, 100, 100, 100, 100],\n",
       "         [ 28,  68,  91,  39,  87,  41,  55],\n",
       "         [ 95,   3,  18,  37,  30,  93,  17],\n",
       "         [ 26,  15,   3,  20,  92,  72,  74],\n",
       "         [ 52,  24,  58,   3,  13,  24,  81],\n",
       "         [100, 100, 100, 100, 100, 100, 100],\n",
       "         [ 83,  20,  59,  11,  15,  24,  72],\n",
       "         [ 70,  20,  65,  77,  43,  51,  61],\n",
       "         [ 81,  98,  11,  31,  69,  91,  93],\n",
       "         [100, 100, 100, 100, 100, 100, 100]],\n",
       "\n",
       "        [[100, 100, 100, 100, 100, 100, 100],\n",
       "         [ 20,  68,  75,  85,  68,   0,  17],\n",
       "         [ 74,  60,  10,  21,  97,  83,  28],\n",
       "         [ 37,   2,  49,  12,  11,  47,  57],\n",
       "         [ 29,  79,  19,  95,  84,   7,  37],\n",
       "         [100, 100, 100, 100, 100, 100, 100],\n",
       "         [  2,  20,  37,  25,  32,   9,  39],\n",
       "         [ 60,  17,  47,  85,  44,  51,  45],\n",
       "         [ 60,  81,  97,  81,  97,  46,   5],\n",
       "         [100, 100, 100, 100, 100, 100, 100]],\n",
       "\n",
       "        [[100, 100, 100, 100, 100, 100, 100],\n",
       "         [ 29,  40,  40,   5,   6,  42,  50],\n",
       "         [ 27,  68,   4,  46,  93,  29,  95],\n",
       "         [ 68,   4,  81,  44,  27,  89,   9],\n",
       "         [ 55,  39,  85,  63,  74,  67,  37],\n",
       "         [100, 100, 100, 100, 100, 100, 100],\n",
       "         [ 14,  22,  20,  67,  20,  48,  52],\n",
       "         [ 82,  12,  15,  20,  84,  32,  92],\n",
       "         [ 68,  56,  49,  40,  56,  38,  49],\n",
       "         [100, 100, 100, 100, 100, 100, 100]],\n",
       "\n",
       "        [[100, 100, 100, 100, 100, 100, 100],\n",
       "         [ 42,  50,  91,  56,  94,  80,  18],\n",
       "         [ 72,  14,  28,  64,  66,  87,  33],\n",
       "         [ 50,  75,   1,  86,   8,  50,  41],\n",
       "         [ 23,  56,  91,  35,  20,  31,   0],\n",
       "         [100, 100, 100, 100, 100, 100, 100],\n",
       "         [ 68,  33,  36,  64,  91,  63,  26],\n",
       "         [ 26,   2,  60,  21,   5,  93,  17],\n",
       "         [ 44,  64,  51,  16,   9,  89,  58],\n",
       "         [100, 100, 100, 100, 100, 100, 100]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将每个班级第0个学生，第5个学生，第9个学生的全部成绩赋值成满分\n",
    "\n",
    "torch.index_fill(scores, dim = 1, index = torch.tensor([0, 5, 9]), value = 100)\n",
    "# 等价于scores.index_fill(dim = 1, index = torch.tensor([0, 5, 9]), value = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[60, 60, 60, 60, 69, 80, 60],\n",
      "         [60, 68, 91, 60, 87, 60, 60],\n",
      "         [95, 60, 60, 60, 60, 93, 60],\n",
      "         [60, 60, 60, 60, 92, 72, 74],\n",
      "         [60, 60, 60, 60, 60, 60, 81],\n",
      "         [79, 60, 60, 81, 99, 69, 60],\n",
      "         [83, 60, 60, 60, 60, 60, 72],\n",
      "         [70, 60, 65, 77, 60, 60, 61],\n",
      "         [81, 98, 60, 60, 69, 91, 93],\n",
      "         [94, 60, 60, 60, 60, 60, 94]],\n",
      "\n",
      "        [[88, 60, 60, 60, 60, 60, 69],\n",
      "         [60, 68, 75, 85, 68, 60, 60],\n",
      "         [74, 60, 60, 60, 97, 83, 60],\n",
      "         [60, 60, 60, 60, 60, 60, 60],\n",
      "         [60, 79, 60, 95, 84, 60, 60],\n",
      "         [60, 60, 61, 69, 60, 60, 73],\n",
      "         [60, 60, 60, 60, 60, 60, 60],\n",
      "         [60, 60, 60, 85, 60, 60, 60],\n",
      "         [60, 81, 97, 81, 97, 60, 60],\n",
      "         [60, 84, 60, 60, 60, 60, 60]],\n",
      "\n",
      "        [[60, 77, 77, 60, 81, 60, 60],\n",
      "         [60, 60, 60, 60, 60, 60, 60],\n",
      "         [60, 68, 60, 60, 93, 60, 95],\n",
      "         [68, 60, 81, 60, 60, 89, 60],\n",
      "         [60, 60, 85, 63, 74, 67, 60],\n",
      "         [60, 60, 77, 89, 84, 60, 60],\n",
      "         [60, 60, 60, 67, 60, 60, 60],\n",
      "         [82, 60, 60, 60, 84, 60, 92],\n",
      "         [68, 60, 60, 60, 60, 60, 60],\n",
      "         [60, 60, 60, 90, 60, 60, 99]],\n",
      "\n",
      "        [[68, 60, 60, 74, 60, 60, 60],\n",
      "         [60, 60, 91, 60, 94, 80, 60],\n",
      "         [72, 60, 60, 64, 66, 87, 60],\n",
      "         [60, 75, 60, 86, 60, 60, 60],\n",
      "         [60, 60, 91, 60, 60, 60, 60],\n",
      "         [72, 60, 60, 60, 78, 76, 88],\n",
      "         [68, 60, 60, 64, 91, 63, 60],\n",
      "         [60, 60, 60, 60, 60, 93, 60],\n",
      "         [60, 64, 60, 60, 60, 89, 60],\n",
      "         [91, 60, 64, 60, 60, 60, 66]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 将分数小于60分的分数赋值成60分\n",
    "b = torch.masked_fill(scores, scores < 60, 60)\n",
    "# 等价于b = scores.masked_fill(scores < 60, 60)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、维度变换\n",
    "维度变换相关函数主要有 torch.reshape(或者调用张量的view方法), torch.squeeze, torch.unsqueeze, torch.transpose\n",
    "\n",
    "torch.reshape 可以改变张量的形状。\n",
    "\n",
    "torch.squeeze 可以减少维度。\n",
    "\n",
    "torch.unsqueeze 可以增加维度。\n",
    "\n",
    "torch.transpose 可以交换维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3, 2])\n",
      "tensor([[[[126, 195],\n",
      "          [ 22,  33],\n",
      "          [ 78, 161]],\n",
      "\n",
      "         [[124, 228],\n",
      "          [116, 161],\n",
      "          [ 88, 102]],\n",
      "\n",
      "         [[  5,  43],\n",
      "          [ 74, 132],\n",
      "          [177, 204]]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 张量的view方法有时候会调用失败，可以使用reshape方法。\n",
    "\n",
    "torch.manual_seed(0)\n",
    "minval, maxval = 0, 255\n",
    "a = (minval + (maxval - minval) * torch.rand([1, 3, 3, 2])).int()\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6])\n",
      "tensor([[126, 195,  22,  33,  78, 161],\n",
      "        [124, 228, 116, 161,  88, 102],\n",
      "        [  5,  43,  74, 132, 177, 204]], dtype=torch.int32)\n",
      "torch.Size([3, 6])\n",
      "tensor([[126, 195,  22,  33,  78, 161],\n",
      "        [124, 228, 116, 161,  88, 102],\n",
      "        [  5,  43,  74, 132, 177, 204]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 改成 （3,6）形状的张量\n",
    "\n",
    "b_1 = a.view([3, 6])\n",
    "print(b_1.shape)\n",
    "print(b_1)\n",
    "\n",
    "b_2 = a.reshape([3, 6])\n",
    "print(b_2.shape)\n",
    "print(b_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3, 2])\n",
      "tensor([[[[126, 195],\n",
      "          [ 22,  33],\n",
      "          [ 78, 161]],\n",
      "\n",
      "         [[124, 228],\n",
      "          [116, 161],\n",
      "          [ 88, 102]],\n",
      "\n",
      "         [[  5,  43],\n",
      "          [ 74, 132],\n",
      "          [177, 204]]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 改回成 [1,3,3,2] 形状的张量\n",
    "\n",
    "c = torch.reshape(b_1, [1, 3, 3, 2])\n",
    "print(c.shape)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果张量在某个维度上只有一个元素，利用torch.squeeze可以消除这个维度。\n",
    "\n",
    "torch.unsqueeze的作用和torch.squeeze的作用相反。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.]])\n",
      "torch.Size([1, 2])\n",
      "tensor([1., 2.])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1.0, 2.0]])\n",
    "s = torch.squeeze(a)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "\n",
    "print(s)\n",
    "print(s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.])\n",
      "torch.Size([2])\n",
      "tensor([[1., 2.]])\n",
      "torch.Size([1, 2])\n",
      "tensor([[1.],\n",
      "        [2.]])\n",
      "torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "# 在第0维插入长度为1的一个维度\n",
    "d_1 = torch.unsqueeze(s, axis = 0)  \n",
    "\n",
    "# 在第1维插入长度为1的一个维度\n",
    "d_2 = torch.unsqueeze(s, axis = 1)  \n",
    "\n",
    "print(s)\n",
    "print(s.shape)\n",
    "\n",
    "print(d_1)\n",
    "print(d_1.shape)\n",
    "\n",
    "print(d_2)\n",
    "print(d_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.transpose可以交换张量的维度，torch.transpose常用于图片存储格式的变换上。\n",
    "\n",
    "如果是二维的矩阵，通常会调用矩阵的转置方法 matrix.t()，等价于 torch.transpose(matrix, 0, 1)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 256, 256, 4])\n",
      "torch.Size([100, 4, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "minval=0\n",
    "maxval=255\n",
    "\n",
    "# Batch, Height, Width, Channel\n",
    "data = torch.floor(minval + (maxval - minval) * torch.rand([100, 256, 256, 4])).int()\n",
    "print(data.shape)\n",
    "\n",
    "# 转换成 Pytorch默认的图片格式 Batch, Channel, Height, Width \n",
    "# 需要交换两次\n",
    "data_t = torch.transpose(torch.transpose(data, 1, 2), 1, 3)\n",
    "# 等价于data_t = torch.transpose(torch.transpose(data, 2, 3), 1, 2)，方法不唯一\n",
    "print(data_t.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "matrix = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(matrix)\n",
    "print(matrix.t()) #等价于torch.transpose(matrix, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、合并分割\n",
    "可以用torch.cat方法和torch.stack方法将多个张量合并，可以用torch.split方法把一个张量分割成多个张量。\n",
    "\n",
    "torch.cat和torch.stack有略微的区别，torch.cat是连接，不会增加维度，而torch.stack是堆叠，会增加维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2])\n",
      "tensor([[ 1.,  2.],\n",
      "        [ 3.,  4.],\n",
      "        [ 5.,  6.],\n",
      "        [ 7.,  8.],\n",
      "        [ 9., 10.],\n",
      "        [11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "b = torch.tensor([[5.0, 6.0], [7.0, 8.0]])\n",
    "c = torch.tensor([[9.0, 10.0], [11.0, 12.0]])\n",
    "\n",
    "abc_cat = torch.cat([a, b, c], dim = 0)\n",
    "print(abc_cat.shape)\n",
    "print(abc_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.],\n",
       "        [ 3.,  4.],\n",
       "        [ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.],\n",
       "        [11., 12.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([a, b, c], axis = 0) # torch中dim和axis参数名可以混用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  5.,  6.,  9., 10.],\n",
       "        [ 3.,  4.,  7.,  8., 11., 12.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([a, b, c], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 2])\n",
      "tensor([[[ 1.,  2.],\n",
      "         [ 3.,  4.]],\n",
      "\n",
      "        [[ 5.,  6.],\n",
      "         [ 7.,  8.]],\n",
      "\n",
      "        [[ 9., 10.],\n",
      "         [11., 12.]]])\n"
     ]
    }
   ],
   "source": [
    "abc_stack = torch.stack([a, b, c], axis = 0) \n",
    "print(abc_stack.shape)\n",
    "print(abc_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.],\n",
       "         [ 5.,  6.],\n",
       "         [ 9., 10.]],\n",
       "\n",
       "        [[ 3.,  4.],\n",
       "         [ 7.,  8.],\n",
       "         [11., 12.]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([a, b, c], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.],\n",
      "        [ 3.,  4.],\n",
      "        [ 5.,  6.],\n",
      "        [ 7.,  8.],\n",
      "        [ 9., 10.],\n",
      "        [11., 12.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[5., 6.],\n",
      "        [7., 8.]])\n",
      "tensor([[ 9., 10.],\n",
      "        [11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.split是torch.cat的逆运算，可以指定分割份数平均分割，也可以通过指定每份的记录数量进行分割。\n",
    "print(abc_cat)\n",
    "a, b, c = torch.split(abc_cat, split_size_or_sections = 2, dim = 0) #每份2个进行分割\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.],\n",
      "        [ 3.,  4.],\n",
      "        [ 5.,  6.],\n",
      "        [ 7.,  8.],\n",
      "        [ 9., 10.],\n",
      "        [11., 12.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.],\n",
      "        [7., 8.]])\n",
      "tensor([[ 9., 10.]])\n",
      "tensor([[11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "print(abc_cat)\n",
    "p, q, r = torch.split(abc_cat, split_size_or_sections =[4, 1, 1], dim = 0) # 每份分别为[4,1,1]\n",
    "print(p)\n",
    "print(q)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
